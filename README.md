Открывать решение следует с помощью Jupiter Notebook. 
Архив dataset(7300) распаковать таким образом, чтобы картинки и new_main.ipynb находились в одной папке.
При решении использовал элементы кодов, с помощью которых решал задачи на Coursera в специализации "Машинное обучение и анализ данных".
Ход решения описан внутри. Запускать незакомментированные ячейки.
Продублирую ключевые моменты здесь.


Я отложил 100 изображений (50 часов и 50 крокодилов) для теста. Остальные 900 поворачиваем 3 раза, и делаем зеркальное отражение для каждой получившейся. Таким обазом, мы расширяем датасет, на котором обучаемся (теперь 7200 изображений)
В качестве признаков я использовал:
1.Сумму по R, G, B каналам (3 нормированных числа)
2.Гистограмма от черно-белой картинки. Она представляет из себя длинный вектор, который я разбиваю на 4 части и в каждой из частей усредняю числа. Аналогично для гистограмм от R, G, B каналов от цветной картинки. (В итоге 4 гистограммы)
3.Вектор, который выдает метод HOG (библиотека skimage), или гистограммы направленных градиентов

  Accuracy на кросс-валидации трейна получился 0.945, на тестовой выборке accuracy=0.93.
Для поиска картинок, похожих и на то, и на то я посчитал вероятности принадлежности всех к картинок к своим классам. Близки к 0.5 (машина не уверена): 2072.png, 2352.png, 3032.png, 7204.png, 7240.png
  На 2072.png и 3032.png, как мне кажется, действительно неочевидно. Мы можем понять, что это часы только благодаря циферблату.
  
  Я думаю, что результат можно улучшить. Во-первых, я не успел разобраться в том, как работает HOG, может быть надо было варьировать его параметры и сильно укоротить выдаваемый вектор. Так же, надо лучше поработать с набором обычных признаков, возможно было нецелесообразно добавлять гистограммы в том виде, в котором делал я. Во-вторых, здесь могли лучше сработать методы, которые используют словарь визуальных слов или выделяют геометрические формы, это помогло бы для отделения часов (ну и конечно, deeplearning)
